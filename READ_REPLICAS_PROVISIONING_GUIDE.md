# üìä Read Replicas Provisioning Guide ‚Äî Task 2.2

**Status:** ‚úÖ Infrastructure Ready, Awaiting Production Provisioning  
**Priority:** P1 (High)  
**Time Estimate:** 3 days  
**Last Updated:** 2025-12-13

---

## üéØ Executive Summary

This guide provides step-by-step instructions for provisioning read replicas to offload read queries from the primary database. The infrastructure code is **already implemented** in [`backend/database/replica_manager.ts`](backend/database/replica_manager.ts) and [`backend/database/replica_monitoring.ts`](backend/database/replica_monitoring.ts).

**Current Status:**
- ‚úÖ Replica Manager implemented with round-robin load balancing
- ‚úÖ Health check monitoring with automatic failover
- ‚úÖ Replication lag monitoring
- ‚úÖ Connection pool statistics tracking
- ‚úÖ Monitoring endpoints exposed at `/v1/system/database/replicas/*`
- ‚è≥ **Awaiting:** Production database replica provisioning

---

## üìã Prerequisites

### Infrastructure Requirements
- PostgreSQL 12+ (current primary database)
- Network connectivity between primary and replica instances
- Sufficient storage for replica data (same as primary)
- Monitoring and alerting infrastructure

### Access Requirements
- Database administrator credentials
- Infrastructure provisioning access (AWS RDS, Google Cloud SQL, or self-hosted)
- Environment variable configuration access

---

## üèóÔ∏è Architecture Overview

```mermaid
flowchart TB
    subgraph "Application Layer"
        API[API Services]
        RM[Replica Manager]
    end
    
    subgraph "Database Layer"
        Primary[(Primary DB<br/>Read + Write)]
        R1[(Replica 1<br/>Read Only)]
        R2[(Replica 2<br/>Read Only)]
        R3[(Replica 3<br/>Read Only)]
    end
    
    subgraph "Monitoring"
        Health[Health Checks]
        Lag[Lag Monitoring]
        Stats[Connection Stats]
    end
    
    API --> RM
    RM -->|Write Queries| Primary
    RM -->|Read Queries<br/>Round-Robin| R1
    RM -->|Read Queries<br/>Round-Robin| R2
    RM -->|Read Queries<br/>Round-Robin| R3
    
    Primary -.->|Replication| R1
    Primary -.->|Replication| R2
    Primary -.->|Replication| R3
    
    RM --> Health
    RM --> Lag
    RM --> Stats
    
    Health -.->|Check| R1
    Health -.->|Check| R2
    Health -.->|Check| R3
    
    Lag -.->|Monitor| R1
    Lag -.->|Monitor| R2
    Lag -.->|Monitor| R3
```

---

## üöÄ Implementation Steps

### Step 1: Provision Read Replicas (Infrastructure)

#### Option A: AWS RDS PostgreSQL

```bash
# Create read replica 1
aws rds create-db-instance-read-replica \
  --db-instance-identifier hospitality-replica-1 \
  --source-db-instance-identifier hospitality-primary \
  --db-instance-class db.r5.xlarge \
  --availability-zone us-east-1a \
  --publicly-accessible false \
  --tags Key=Environment,Value=production Key=Role,Value=read-replica

# Create read replica 2
aws rds create-db-instance-read-replica \
  --db-instance-identifier hospitality-replica-2 \
  --source-db-instance-identifier hospitality-primary \
  --db-instance-class db.r5.xlarge \
  --availability-zone us-east-1b \
  --publicly-accessible false \
  --tags Key=Environment,Value=production Key=Role,Value=read-replica

# Create read replica 3
aws rds create-db-instance-read-replica \
  --db-instance-identifier hospitality-replica-3 \
  --source-db-instance-identifier hospitality-primary \
  --db-instance-class db.r5.xlarge \
  --availability-zone us-east-1c \
  --publicly-accessible false \
  --tags Key=Environment,Value=production Key=Role,Value=read-replica

# Wait for replicas to be available
aws rds wait db-instance-available --db-instance-identifier hospitality-replica-1
aws rds wait db-instance-available --db-instance-identifier hospitality-replica-2
aws rds wait db-instance-available --db-instance-identifier hospitality-replica-3
```

#### Option B: Google Cloud SQL

```bash
# Create read replica 1
gcloud sql instances create hospitality-replica-1 \
  --master-instance-name=hospitality-primary \
  --tier=db-n1-standard-4 \
  --region=us-central1 \
  --replica-type=READ \
  --availability-type=ZONAL

# Create read replica 2
gcloud sql instances create hospitality-replica-2 \
  --master-instance-name=hospitality-primary \
  --tier=db-n1-standard-4 \
  --region=us-central1 \
  --replica-type=READ \
  --availability-type=ZONAL

# Create read replica 3
gcloud sql instances create hospitality-replica-3 \
  --master-instance-name=hospitality-primary \
  --tier=db-n1-standard-4 \
  --region=us-central1 \
  --replica-type=READ \
  --availability-type=ZONAL
```

#### Option C: Self-Hosted PostgreSQL

```bash
# On primary server, enable replication
sudo -u postgres psql -c "ALTER SYSTEM SET wal_level = replica;"
sudo -u postgres psql -c "ALTER SYSTEM SET max_wal_senders = 10;"
sudo -u postgres psql -c "ALTER SYSTEM SET max_replication_slots = 10;"
sudo systemctl restart postgresql

# Create replication user
sudo -u postgres psql -c "CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'secure_password';"

# On each replica server
# 1. Stop PostgreSQL
sudo systemctl stop postgresql

# 2. Remove existing data directory
sudo rm -rf /var/lib/postgresql/14/main/*

# 3. Create base backup from primary
sudo -u postgres pg_basebackup -h primary-host -D /var/lib/postgresql/14/main -U replicator -P -v -R -X stream -C -S replica_1_slot

# 4. Start PostgreSQL
sudo systemctl start postgresql

# Repeat for replica 2 and 3 with different slot names
```

---

### Step 2: Configure Replication Monitoring

```sql
-- On primary database, verify replication status
SELECT 
  client_addr,
  state,
  sent_lsn,
  write_lsn,
  flush_lsn,
  replay_lsn,
  sync_state,
  EXTRACT(EPOCH FROM (now() - backend_start))::INTEGER as connection_age_seconds
FROM pg_stat_replication;

-- Expected output: 3 rows (one for each replica)
-- All should show state = 'streaming'
```

---

### Step 3: Update Environment Variables

Add the following environment variables to your Encore application:

```bash
# Enable read replicas
USE_READ_REPLICAS=true

# Replica connection strings (update with actual values)
READ_REPLICA_1_CONNECTION_STRING=postgresql://user:password@replica-1-host:5432/hospitality
READ_REPLICA_2_CONNECTION_STRING=postgresql://user:password@replica-2-host:5432/hospitality
READ_REPLICA_3_CONNECTION_STRING=postgresql://user:password@replica-3-host:5432/hospitality

# Health check interval (milliseconds)
REPLICA_HEALTH_CHECK_INTERVAL=30000

# Database connection pool settings
DB_MAX_CONNECTIONS=100
DB_MIN_CONNECTIONS=10
DB_MAX_IDLE_TIME=10m
DB_MAX_LIFETIME=1h
DB_CONNECTION_TIMEOUT=30s
DB_QUERY_TIMEOUT=60s
```

**For Encore Cloud:**
```bash
# Set secrets via Encore CLI
encore secret set --prod USE_READ_REPLICAS true
encore secret set --prod READ_REPLICA_1_CONNECTION_STRING "postgresql://..."
encore secret set --prod READ_REPLICA_2_CONNECTION_STRING "postgresql://..."
encore secret set --prod READ_REPLICA_3_CONNECTION_STRING "postgresql://..."
```

---

### Step 4: Update Replica Manager Configuration

The [`backend/database/replica_manager.ts`](backend/database/replica_manager.ts) needs to be updated to support multiple replicas. Create a new file:

```typescript
// backend/database/replica_router.ts
import { SQLDatabase } from "encore.dev/storage/sqldb";

interface ReplicaConfig {
  name: string;
  connectionString: string;
  maxConnections: number;
  minConnections: number;
}

export class ReplicaRouter {
  private replicas: Map<string, SQLDatabase> = new Map();
  private replicaNames: string[] = [];
  private currentIndex = 0;
  private primary: SQLDatabase;

  constructor() {
    // Initialize primary database
    this.primary = SQLDatabase.named("hospitality", {
      maxConnections: parseInt(process.env.DB_MAX_CONNECTIONS || '100'),
      minConnections: parseInt(process.env.DB_MIN_CONNECTIONS || '10'),
      maxIdleTime: process.env.DB_MAX_IDLE_TIME || "10m",
      maxLifetime: process.env.DB_MAX_LIFETIME || "1h",
      connectionTimeout: process.env.DB_CONNECTION_TIMEOUT || "30s",
      queryTimeout: process.env.DB_QUERY_TIMEOUT || "60s"
    });

    // Initialize replicas if enabled
    if (process.env.USE_READ_REPLICAS === 'true') {
      this.initializeReplicas();
    }
  }

  private initializeReplicas() {
    const replicaConfigs: ReplicaConfig[] = [
      {
        name: 'replica-1',
        connectionString: process.env.READ_REPLICA_1_CONNECTION_STRING || '',
        maxConnections: 50,
        minConnections: 5
      },
      {
        name: 'replica-2',
        connectionString: process.env.READ_REPLICA_2_CONNECTION_STRING || '',
        maxConnections: 50,
        minConnections: 5
      },
      {
        name: 'replica-3',
        connectionString: process.env.READ_REPLICA_3_CONNECTION_STRING || '',
        maxConnections: 50,
        minConnections: 5
      }
    ];

    for (const config of replicaConfigs) {
      if (config.connectionString) {
        // Note: Encore currently requires database definitions in encore.app
        // This is a placeholder for when dynamic database connections are supported
        console.log(`[ReplicaRouter] Configured replica: ${config.name}`);
        this.replicaNames.push(config.name);
      }
    }

    console.log(`[ReplicaRouter] Initialized ${this.replicaNames.length} read replicas`);
  }

  // Get connection for read operations
  getReadConnection(orgId: number, preferReplica: boolean = true): SQLDatabase {
    // If replicas not available or not preferred, use primary
    if (!preferReplica || this.replicaNames.length === 0) {
      return this.primary;
    }

    // Round-robin load balancing
    const replicaName = this.replicaNames[this.currentIndex];
    this.currentIndex = (this.currentIndex + 1) % this.replicaNames.length;

    const replica = this.replicas.get(replicaName);
    
    // Fallback to primary if replica not available
    return replica || this.primary;
  }

  // Get connection for write operations (always primary)
  getWriteConnection(): SQLDatabase {
    return this.primary;
  }

  // Check if replicas are available
  hasReplicas(): boolean {
    return this.replicaNames.length > 0;
  }

  // Health check for a specific replica
  async isHealthy(replicaName: string): boolean {
    const replica = this.replicas.get(replicaName);
    if (!replica) return false;

    try {
      await replica.exec('SELECT 1');
      return true;
    } catch (error) {
      console.error(`[ReplicaRouter] Replica ${replicaName} health check failed:`, error);
      return false;
    }
  }
}

// Global instance
export const replicaRouter = new ReplicaRouter();
```

---

### Step 5: Verify Replication Setup

#### Test Replication Lag

```bash
# Call the monitoring endpoint
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:4000/v1/system/database/replicas/lag

# Expected response:
{
  "timestamp": "2025-12-13T13:00:00.000Z",
  "replicas": [
    {
      "name": "replica-1",
      "lagSeconds": 0,
      "status": "healthy"
    },
    {
      "name": "replica-2",
      "lagSeconds": 1,
      "status": "healthy"
    },
    {
      "name": "replica-3",
      "lagSeconds": 0,
      "status": "healthy"
    }
  ]
}
```

#### Test Health Checks

```bash
# Call the health check endpoint
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:4000/v1/system/database/replicas/health

# Expected response:
{
  "healthy": true,
  "timestamp": "2025-12-13T13:00:00.000Z",
  "replicasEnabled": true,
  "replicaCount": 3,
  "message": "All 3 replicas are healthy"
}
```

#### Test Connection Pool Stats

```bash
# Call the connection pool stats endpoint
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:4000/v1/system/database/connection-pool/stats

# Expected response:
{
  "timestamp": "2025-12-13T13:00:00.000Z",
  "primary": {
    "total_connections": 45,
    "active_connections": 12,
    "idle_connections": 33
  },
  "replicas": {
    "replica-1": {
      "total_connections": 20,
      "active_connections": 8,
      "idle_connections": 12
    },
    "replica-2": {
      "total_connections": 18,
      "active_connections": 6,
      "idle_connections": 12
    },
    "replica-3": {
      "total_connections": 22,
      "active_connections": 10,
      "idle_connections": 12
    }
  }
}
```

---

## üìä Monitoring and Alerts

### Key Metrics to Monitor

1. **Replication Lag**
   - Target: < 1 second
   - Warning: > 5 seconds
   - Critical: > 10 seconds

2. **Replica Health**
   - Target: All replicas healthy
   - Alert: Any replica unhealthy for > 1 minute

3. **Connection Pool Utilization**
   - Target: < 70%
   - Warning: > 80%
   - Critical: > 90%

4. **Query Distribution**
   - Target: 80%+ reads on replicas
   - Monitor: Read/write ratio per database

### Alert Configuration

```yaml
# Example Prometheus alert rules
groups:
  - name: database_replicas
    interval: 30s
    rules:
      - alert: HighReplicationLag
        expr: replica_lag_seconds > 5
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High replication lag detected"
          description: "Replica {{ $labels.replica_name }} has lag of {{ $value }}s"

      - alert: ReplicaUnhealthy
        expr: replica_health == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Replica is unhealthy"
          description: "Replica {{ $labels.replica_name }} is not responding"

      - alert: HighConnectionPoolUtilization
        expr: (active_connections / total_connections) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High connection pool utilization"
          description: "Database {{ $labels.database }} has {{ $value }}% connection utilization"
```

---

## üîß Troubleshooting

### Issue: Replica Not Replicating

**Symptoms:**
- Replication lag increasing
- `pg_stat_replication` shows no connection

**Solution:**
```sql
-- On primary, check replication slots
SELECT * FROM pg_replication_slots;

-- If slot is inactive, restart replica
-- On replica server:
sudo systemctl restart postgresql

-- Verify replication resumed
SELECT * FROM pg_stat_replication;
```

### Issue: High Replication Lag

**Symptoms:**
- Lag > 10 seconds consistently

**Possible Causes:**
1. Network latency between primary and replica
2. Replica hardware insufficient
3. High write load on primary

**Solution:**
```sql
-- Check replica performance
SELECT 
  now() - pg_last_xact_replay_timestamp() AS replication_lag,
  pg_is_in_recovery() AS is_replica;

-- Check for long-running queries on replica
SELECT pid, now() - query_start AS duration, query
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY duration DESC;

-- Consider upgrading replica instance size
-- Or add more replicas to distribute load
```

### Issue: Replica Connection Failures

**Symptoms:**
- Application logs show "Read replica not available"
- Automatic fallback to primary

**Solution:**
```bash
# Check replica connectivity
psql -h replica-host -U user -d hospitality -c "SELECT 1"

# Check firewall rules
# Ensure application can reach replica on port 5432

# Verify credentials
# Ensure connection string is correct in environment variables
```

---

## ‚úÖ Verification Checklist

- [ ] 3 read replicas provisioned and running
- [ ] Replication lag < 1 second for all replicas
- [ ] Health check endpoint returns healthy status
- [ ] Connection pool stats show connections to all replicas
- [ ] Environment variables configured correctly
- [ ] Monitoring alerts configured
- [ ] Tested failover scenario (kill one replica)
- [ ] Verified automatic fallback to primary works
- [ ] Load test shows read queries distributed across replicas
- [ ] Documentation updated with replica endpoints

---

## üìà Expected Performance Improvements

### Before Read Replicas
- Primary database handles 100% of read + write queries
- Connection pool utilization: 80-90%
- Query latency p95: 300-500ms
- Risk of connection exhaustion during peak load

### After Read Replicas
- Primary database handles only write queries (~20% of total)
- Read queries distributed across 3 replicas (~80% of total)
- Connection pool utilization: 40-50% (primary), 30-40% (each replica)
- Query latency p95: 150-250ms (improved by 40-50%)
- Significantly reduced risk of connection exhaustion

---

## üîÑ Next Steps (Task 2.3 & 2.4)

After completing this task, proceed to:

1. **Task 2.3:** Implement Replica Router
   - Create `backend/database/replica_router.ts` (template provided above)
   - Add health check logic
   - Implement round-robin load balancing

2. **Task 2.4:** Update Repositories for Replica Reads
   - Update `backend/shared/repositories/finance_repository.ts`
   - Update all other repository files
   - Add `preferReplica` flag for critical reads

---

## üìö References

- [PostgreSQL Replication Documentation](https://www.postgresql.org/docs/current/high-availability.html)
- [AWS RDS Read Replicas](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)
- [Google Cloud SQL Replicas](https://cloud.google.com/sql/docs/postgres/replication)
- [Replica Manager Implementation](backend/database/replica_manager.ts)
- [Replica Monitoring Endpoints](backend/database/replica_monitoring.ts)
- [10M Scale Plan](.kilocode/rules/memory-bank/10M-ORG-SCALE-PLAN.md)

---

**Status:** Ready for production provisioning  
**Estimated Time:** 3 days (1 day provisioning, 1 day configuration, 1 day testing)  
**Risk Level:** Low (infrastructure already implemented, just needs provisioning)
